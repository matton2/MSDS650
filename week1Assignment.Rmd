---
title: "Week1 DataAnalytics"
author: "Matthew Onimus"
date: "3/8/2020"
output:
  html_document:
    theme: "spacelab"
    code_folding: show
    toc: true
    toc_float:
      collapsed: false
      smooth_scoll: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
packages <- c("tidyverse", "kableExtra", 'data.table')
purrr::walk(packages, library, character.only = TRUE)
```

## Let's Investigate the Iris Dataset 

I have already loaded in the packages `r paste(packages, collapse = ", ")` to be used for this anaylsis.  After paging through the assignment it seems pretty straightforward so I will probably not be adding quite that much text to this document and will execute most of the assignment in the same code chunk. 


```{r soMuchCode}

# check out the structure of iris
str(iris)

# find some summary stats of iris
summary(iris)

# use head to display the first n = 10 rows with some kable style to make it look pretty
kable(head(iris, n = 10)) %>% kable_styling()

# i already loaded up the data.table package at the start of the script, I am going to perform the analysis both the example way and also the tidyverse way just to make sure I can do it

DT <- as.data.table(iris)

# Begin the summary functions, I personally find the tidyverse way so much easier to read and code review

# summary exercise 1
DT[,mean(Sepal.Length), by=Species]

iris %>% 
  group_by(Species) %>% 
  summarise(meanSepalLength = mean(Sepal.Length)) %>% 
  kable() %>% 
  kable_styling()

# summary exercise 2

DT[, mean(Sepal.Length), by = substring(Species, 1, 1)]

iris %>% 
  mutate(Species = str_sub(Species, 1, 1)) %>% 
  group_by(Species) %>% 
  summarise(meanSepalLength = mean(Sepal.Length)) %>% 
  kable() %>% 
  kable_styling()

# summary exercise 3

DT[, .N, by = 10 * round(Sepal.Length * Sepal.Width/10)]

iris %>% 
  mutate(newVariable = 10 * round(Sepal.Length * Sepal.Width/10)) %>% 
  group_by(newVariable) %>% 
  summarise(totalCount = n()) %>% 
  kable() %>% 
  kable_styling()

# summary exercise 4

DT[, .(Count = .N), by = .(Area = 10 * round(Sepal.Length * Sepal.Width/10))]

# see exercise about for tidyverse version

# Chaining exercises, same as above DT and tidyverse below

# chaining exercise 1

DT[, .(Sepal_length = median(Sepal.Length),
       Sepal_width = median(Sepal.Width),
       Petal_length = median(Petal.Length),
       Petal_width = median(Petal.Width)),
   by = Species][order(-Species)]

iris %>% 
  group_by(Species) %>% 
  summarize(Sepel_length = median(Sepal.Length),
         Sepal_width = median(Sepal.Width),
         Petal_length = median(Petal.Length),
         Petal_width = median(Petal.Width)) %>% 
  arrange(desc(Species)) %>% 
  kable() %>% 
  kable_styling()

# chaining exercise 2

DT[, .(Sepal_length = mean(Sepal.Length),
       Sepal_width = mean(Sepal.Width),
       Petal_length = mean(Petal.Length),
       Petal_width = mean(Petal.Width)),
   by = Species][order(Species)]

iris %>% 
  group_by(Species) %>% 
  summarize(Sepel_length = mean(Sepal.Length),
         Sepal_width = mean(Sepal.Width),
         Petal_length = mean(Petal.Length),
         Petal_width = mean(Petal.Width)) %>% 
  arrange(Species) %>% 
  kable() %>% 
  kable_styling()

# Subsetting exercise, same as above

# subsetting exercise 1

DT[, lapply(.SD, mean), by = Species]

iris %>% 
  group_by(Species) %>% 
  summarise_all(funs(mean)) %>% 
  kable() %>% 
  kable_styling()


# subsetting exercise 2

DT[, lapply(.SD, max), by = Species]

iris %>% 
  group_by(Species) %>% 
  summarise_all(funs(max)) %>% 
  kable() %>% 
  kable_styling()

# Additional commands section

# all the DT commands first



DT1 <- DT[Species == 'virginica']

head(DT1)

DT2 <- DT[Species %in% c('virginica', 'versicolor')]

head(DT2)
tail(DT2)

setnames(DT, gsub("^Sepal[.]", "",names(DT)))
DT <- DT[,grep("^Petal", names(DT)) := NULL]

head(DT)

DT[Width * Length > 20]


# some tidyverse commands

iris %>% 
  filter(Species == 'virginica') %>% 
  head() %>% 
  kable() %>% 
  kable_styling()


iris %>% 
  filter(Species %in% c("virginica", "versicolor")) %>% 
  slice(1:5, 95:100) %>% 
  kable() %>% 
  kable_styling()

iris1  <- iris %>%
  set_names(~ str_replace_all((.), "^Sepal[.]", "")) 

irisFinal <- iris1 %>% 
  set_names(~ str_replace_all((.), "Petal[.]", "")) %>%
  bind_rows(iris1) %>% 
  select(-c(Petal.Length, Petal.Width)) 

irisFinal %>% 
  head() %>% 
  kable() %>% 
  kable_styling()

irisFinal %>% 
  filter(Width * Length > 20) %>% 
  head() %>% 
  kable() %>% 
  kable_styling()
  
  

```
## Choose Your Own Adventure

I have choosen the a dataset from Lehman baseball stats.  I have used this data set before in MSDS 600 to do some prediction.  Here I will just execute some filters and grouping to see some summary stats.

```{r baseballTime}

# first thing is to bring in the batting stats and the appearances since I want to pull about some position stuff (maybe)
baseballStat <- Lahman::Batting
baseballPlayers <- Lahman::Appearances

# there are over 100,000 observations in batter stats, here are the summary stats
summary(baseballStat) %>% 
  kable() %>% 
  kable_styling()

# first think I want to do is just take a look at stats from 1990 and later and then join with the playerIDs, next i am going to remove any observations with less than 100 abs, next I want to gather the Pos data so i do some filtering on that, next i will remove some columns i dont care about, and finally i filter out all the games that that player played less than 10 games at

baseball1990 <- baseballStat %>% 
  filter(yearID >= 1990) %>% 
  left_join(baseballPlayers) %>% 
  filter(AB > 100) %>% 
  gather(G_c, G_1b, G_2b, G_3b, G_ss, G_of, G_dh, key = 'pos', value = 'GP') %>% 
  select(-c(G_all, GS, G_batting, G_defense, G_p, G_lf, G_rf, G_cf, G_ph, G_pr, stint, teamID, lgID)) %>% 
  filter(GP > 10)

# now that we have this nice little dataframe, lets do some stats based on position grouping

baseball1990 %>% 
  group_by(pos) %>% 
  summarise(avgHr = mean(HR)) %>% 
  kable() %>% 
  kable_styling()

# lets do some additional grouping and see if we can see some trend in terms of OF HR and SO, I think we are going to see something interesting

baseball1990 %>% 
  filter(pos == 'G_of') %>% 
  group_by(yearID) %>% 
  summarise(avgHR = mean(HR),
            avgSO = mean(SO)) %>% 
  kable() %>% 
  kable_styling()

# finally, let's take a look at min and max values for SO and HR for OF again to see if we can see a trend there

baseball1990 %>% 
  filter(pos == "G_of") %>% 
  group_by(yearID) %>% 
  summarize(minHR = min(HR),
            maxHR = max(HR),
            minSO = min(SO),
            maxSO = max(SO)) %>% 
  kable() %>% 
  kable_styling()



```

What we have learned, the Lahman dataset is definitely one of my favorites.  Average outfielder power has not increased really since 1990 but the strikeouts certainly have.